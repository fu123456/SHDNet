<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>README.html</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>

</head>

<body>

<h1>Overview</h1>

<p>This is the project about our SHDNet.</p>

<p><a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413586">Paper</a>, <a href="http://graphvision.whu.edu.cn/papers/supplement_SHDNet.pdf">Supplement</a>, and <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413586">Video</a></p>

<p><img src="images/introduction.png" alt="Comparison with state-of-the-art highlight detection methods on an example image with very bright texts and materials." />
<em>Comparison with state-of-the-art highlight detection methods on an example image with very bright texts and materials.</em></p>

<p>Learning to Detect Specular Highlights from Real-world Images</p>

<p><a href="https://github.com/fu123456">Gang Fu</a>, <a href="http://zhangqing-home.net/">Qing Zhang</a>, QiFeng Lin, <a href="">Lei Zhu</a>, and <a href="http://graphvision.whu.edu.cn/">Chunaxia Xiao</a></p>

<p><a href="https://2020.acmmm.org/">ACM Multimedia 2020</a></p>

<p>Specular highlight detection is a challenging problem, and has many
applications such as shiny object detection and light source
estimation. Although various highlight detection methods have been
proposed, they fail to disambiguate bright material surfaces from
highlights, and cannot handle non-white-balanced images. Moreover, at
present, there is still no benchmark dataset for highlight
detection. In this paper, we present a large-scale real-world
highlight dataset containing a rich variety of material categories,
with diverse highlight shapes and appearances, in which each image is
with an annotated ground-truth mask. Based on the dataset, we develop
a deep learning-based specular highlight detection network (SHDNet)
leveraging multi-scale context contrasted features to accurately
detect specular highlights of varying scales. In addition, we design a
binary cross-entropy (BCE) loss and an intersection-over-union edge
(IoUE) loss for our network. Compared with existing highlight
detection methods, our method can accurately detect highlights of
different sizes, while effectively excluding the non- highlight
regions, such as bright materials, non-specular as well as colored
lighting, and even light sources.</p>

<p>If you have any questions about this project, please contact me via
Email: xyzgfu@gmail.com</p>

<h1>WHU-Specular dataset</h1>

<p><img src="images/data_teaser.png" alt="Example highlight images and corresponding highlight masks in our dataset. Please zoom in to view more details." />
<em>Example highlight images and corresponding highlight masks in our dataset. Please zoom in to view more details.</em></p>

<p>WHU-Specular is a large dataset of annotated specular highlight
regions created from real-world images. It can be used for specular
highlight detection task. It contains 4310 image pairs (specular
images and corresponding highlight masks). We randomly selected 3,017
images as the training set, and other 1293 images as the testing set.
<strong>Now, our full dataset is publicly available</strong>. You can download our
dataset (size: 2G+) by Baidu Cloud (Link:
https://pan.baidu.com/s/1UizWty88XNhdI3PSNm0B-Q password: t3ov) and
Google Drive (Link:
https://drive.google.com/file/d/1yLSBr5tfYL-u4RyStX1sPmrJGCVuo0GB/view?usp=sharing.</p>

<p><strong>Statement</strong>. WHU-Specular dataset is intended only for research
purposes and thus cannot be used commercially. Moreover, reference
must be made to the following publication when the dataet is used in
any academic and research reports.</p>

<p><code>text
@inproceedings{fu-2020-learn-detec,
author = {Fu, Gang and Zhang, Qing and Lin, Qifeng and Zhu, Lei and Xiao, Chunxia},
title = {Learning to Detect Specular Highlights from Real-world Images},
booktitle = {ACM Multimedia},
year = {2020},
pages = {1873--1881},
}
</code></p>

<h1>Compared methods</h1>

<h2>Traditional highlight detection methods</h2>

<p>Note that the authors of the paper [2] have not released their
code. Thus we have implemented their algorithm using Matlab ourselves. The code is in
<em>src/highlight_detection_tmi2019</em>.</p>

<p>The code of [3] is available at the project website <a href="https://github.com/muratkrty/specularity-removal">specularity-removal</a>.</p>

<p>The code of [4] is available at the project website <a href="https://github.com/jiemojiemo/some_specular_detection_and_inpainting_methods_for_endoscope_image">some_specular_detection_and_inapinting_methods_for_endoscope_image</a>.</p>

<h2>Other Learning-based detection methods in related fields</h2>

<p>TODO &hellip; &hellip;</p>

<h1>References</h1>

<p>[1] Zhang, W., Zhao, X., Morvan, J., &amp; Chen, L. (2018). Improving
shadow suppression for illumination robust face recognition. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 41(3),
611–624.</p>

<p>[2] Li, R., Pan, J., Si, Y., Yan, B., Hu, Y., &amp; Qin, H. (2019). Specular
reflections removal for endoscopic image sequences with
adaptive-rpca decomposition. IEEE Transactions on Medical Imaging,
39(2), 328–340.</p>

<p>[3] Tchoulack, S., Langlois, J. M. P., &amp; Cheriet, F. (2008). A video
stream processor for real-time detection and correction of specular
reflections in endoscopic images. In , Joint International IEEE
Northeast Workshop on Circuits and Systems and Taisa Conference.</p>

<p>[4] Meslouhi, O., Kardouchi, M., Allali, H., Gadi, T., &amp; Benkaddour,
Y. (2011). Automatic detection and inpainting of specular
reflections for colposcopic images. Open Computer Science, 1(3),
341–354.</p>

<h1>Citation</h1>

<p>If you use our dataset, please cite the following paper:</p>

<p><code>text
@inproceedings{fu-2020-learn-detec,
author = {Fu, Gang and Zhang, Qing and Lin, Qifeng and Zhu, Lei and Xiao, Chunxia},
title = {Learning to Detect Specular Highlights from Real-world Images},
booktitle = {ACM Multimedia},
year = {2020},
pages = {1873--1881},
}
</code></p>

</body>
</html>
